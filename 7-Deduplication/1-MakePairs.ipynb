{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T19:39:34.363660Z",
     "iopub.status.busy": "2023-02-16T19:39:34.363234Z",
     "iopub.status.idle": "2023-02-16T19:39:34.366489Z",
     "shell.execute_reply": "2023-02-16T19:39:34.366057Z",
     "shell.execute_reply.started": "2023-02-16T19:39:34.363642Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This script identifies pairs of potential duplicates \n",
    "# And filters on business name and business status\n",
    "\n",
    "# We use pandas deduplicate functions to remove exact matches\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "# import re\n",
    "from rl_helper import strip_accents, AddressClean, haversine\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.preprocessing import clean\n",
    "# from recordlinkage.index import Block\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import mitosheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T19:39:35.251126Z",
     "iopub.status.busy": "2023-02-16T19:39:35.250156Z",
     "iopub.status.idle": "2023-02-16T19:39:35.254988Z",
     "shell.execute_reply": "2023-02-16T19:39:35.254392Z",
     "shell.execute_reply.started": "2023-02-16T19:39:35.251079Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        import math\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T19:39:35.867293Z",
     "iopub.status.busy": "2023-02-16T19:39:35.866697Z",
     "iopub.status.idle": "2023-02-16T19:39:39.996778Z",
     "shell.execute_reply": "2023-02-16T19:39:39.996109Z",
     "shell.execute_reply.started": "2023-02-16T19:39:35.867271Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length:  558964\n"
     ]
    }
   ],
   "source": [
    "# IMPORT DATA\n",
    "\n",
    "df_input = pd.read_csv(\"~/ODBiz/6-AssignCSDs/NAICS_Final.csv\", low_memory=False, dtype='str')\n",
    "print('input length: ', len(df_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T19:39:39.998328Z",
     "iopub.status.busy": "2023-02-16T19:39:39.997909Z",
     "iopub.status.idle": "2023-02-16T19:39:40.493345Z",
     "shell.execute_reply": "2023-02-16T19:39:40.492755Z",
     "shell.execute_reply.started": "2023-02-16T19:39:39.998292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number removed with business name = NA:  29111\n",
      "Number removed with inactive status:  58598\n"
     ]
    }
   ],
   "source": [
    "# FILTERING\n",
    "\n",
    "df = df_input\n",
    "\n",
    "# Remove any with no business name\n",
    "print('Number removed with business name = NA: ', len(df[df.business_name.isnull()]))\n",
    "df = df[~df.business_name.isnull()]\n",
    "\n",
    "# Remove any with inactive status\n",
    "no_removed = len(df[df.status.isin(['Gone Out of Business', 'Inactive', 'Cancelled'])])\n",
    "print('Number removed with inactive status: ', no_removed)\n",
    "df = df[~df.status.isin(['Gone Out of Business', 'Inactive', 'Cancelled'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T19:39:40.494401Z",
     "iopub.status.busy": "2023-02-16T19:39:40.494109Z",
     "iopub.status.idle": "2023-02-16T19:39:42.874198Z",
     "shell.execute_reply": "2023-02-16T19:39:42.873628Z",
     "shell.execute_reply.started": "2023-02-16T19:39:40.494384Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FORMATTTING\n",
    "\n",
    "# Remove accents\n",
    "text_cols=['business_name','formatted_en']\n",
    "for col in text_cols:\n",
    "    df.loc[~df[col].isnull(),col]=df.loc[~df[col].isnull(),col].apply(strip_accents)\n",
    "\n",
    "# Remove periods, apostrophes, commas, and hypens in the Name and address columns\n",
    "r_list=[r\".\",r\",\",r\"'\",r\"-\"]\n",
    "\n",
    "for r in r_list:\n",
    "    df[\"business_name_2\"] = df[\"business_name\"].str.replace(r,' ',regex=False)\n",
    "    df['formatted_en'] = df['formatted_en'].str.replace(r,' ',regex=False)\n",
    "\n",
    "# Remove excess whitespace\n",
    "df[\"business_name_2\"] = df[\"business_name\"].str.replace(r\" +\",\" \",regex=True)\n",
    "df[\"formatted_en\"] = df[\"formatted_en\"].str.replace(r\" +\",\" \",regex=True)\n",
    "# df['full_address'] = df['full_address'].str.replace(r\" +\",\" \",regex=True)\n",
    "\n",
    "# Standardise postal codes - just remove empty space and make sure it's all lower case\n",
    "# df.loc[~df.postal_code.isnull(),'postal_code'] = df.loc[~df.postal_code.isnull(),'postal_code'].str.replace(' ','').str.lower()\n",
    "\n",
    "# Some records have street number and street name, but no address field filled\n",
    "# df.loc[(df.full_address.isnull())&\\\n",
    "#        (~df.formatted_en.isnull()),'full_address']\\\n",
    "#     = clean(df.loc[(df.full_address.isnull())&\\\n",
    "#        (~df.formatted_en.isnull()),'street_no']+' '+\\\n",
    "#            df.loc[(df.full_address.isnull())&\\\n",
    "#        (~df.formatted_en.isnull()),'formatted_en']+' '+\\\n",
    "#         df.loc[(df.full_address.isnull())&\\\n",
    "#        (~df.formatted_en.isnull()),'city'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T19:39:43.126939Z",
     "iopub.status.busy": "2023-02-16T19:39:43.126305Z",
     "iopub.status.idle": "2023-02-16T19:39:44.082852Z",
     "shell.execute_reply": "2023-02-16T19:39:44.082247Z",
     "shell.execute_reply.started": "2023-02-16T19:39:43.126918Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LABEL DUPLICATES \n",
    "\n",
    "# Deduplicate and filter strictly on name, street number and street name\n",
    "df['dupe_1'] = df.duplicated(subset=['business_name_2', 'street_no', 'formatted_en'], keep=False)\n",
    "\n",
    "# Separate potential duplicates\n",
    "df_non_dup = df[~df['dupe_1'] == True]\n",
    "df =  df[df['dupe_1'] == True]\n",
    "\n",
    "# Sort by street number, then street name, then business name\n",
    "df = df.sort_values(['business_name_2', 'street_no', 'formatted_en'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T19:39:45.807310Z",
     "iopub.status.busy": "2023-02-16T19:39:45.807023Z",
     "iopub.status.idle": "2023-02-16T19:41:30.063282Z",
     "shell.execute_reply": "2023-02-16T19:41:30.062621Z",
     "shell.execute_reply.started": "2023-02-16T19:39:45.807276Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  10000  of  111438\n",
      "Done:  20000  of  111438\n",
      "Done:  30000  of  111438\n",
      "Done:  40000  of  111438\n",
      "Done:  50000  of  111438\n",
      "Done:  60000  of  111438\n",
      "Done:  70000  of  111438\n",
      "Done:  80000  of  111438\n",
      "Done:  90000  of  111438\n",
      "Done:  100000  of  111438\n",
      "Done:  110000  of  111438\n"
     ]
    }
   ],
   "source": [
    "# 3. loop and compare duplicates between rows\n",
    "\n",
    "printcounter = 0\n",
    "col_list = ['business_name_2','licence_number', 'postal_code', 'formatted_en', 'business_sector', 'business_description', 'licence_type', 'primary_NAICS']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    if (printcounter == 10000):\n",
    "        print('Done: ', i, ' of ', len(df))\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    \n",
    "    # check if the street number is the same as the previous row\n",
    "    if (i > 1):\n",
    "        if (df.at[df.index[i],'business_name_2'] == df.at[df.index[i-1],'business_name_2']):\n",
    "            # then street name\n",
    "            if (df.at[df.index[i],'formatted_en'] == df.at[df.index[i-1],'formatted_en']):\n",
    "                # then name\n",
    "                if (df.at[df.index[i],'street_no'] == df.at[df.index[i-1],'street_no']):\n",
    "\n",
    "                    # make a small dataframe with just two rows\n",
    "                    df2 = df.iloc[[i-1, i]]\n",
    "                    df2 = df2[col_list]\n",
    "\n",
    "                    # remove columns which have NA for either value\n",
    "                    df2 = df2.dropna(axis=1)\n",
    "                    \n",
    "                    # if non-NA rows are identical, then mark as duplicate\n",
    "                    if ((df2.iloc[0] == df2.iloc[1]).all()):\n",
    "                        # duplicate\n",
    "                        df.at[df.index[i], 'dupe'] = True\n",
    "                        df.at[df.index[i-1], 'dupe'] = True\n",
    "                        \n",
    "                        # copy values over if one column is null     \n",
    "                        for col in col_list:\n",
    "                            var_1 = df.at[df.index[i-1], col]\n",
    "                            var_2 = df.at[df.index[i], col]\n",
    "\n",
    "                            # if first one is NA and the other isn't\n",
    "                            if (isnan(var_1) & (not isnan(var_2))):\n",
    "                                df.at[df.index[i-1], col] = var_2\n",
    "                        \n",
    "                        # label the one we're going to keep/ remove\n",
    "                        df.at[df.index[i-1], 'keep'] = True\n",
    "                        df.at[df.index[i], 'keep'] = False\n",
    "\n",
    "                        # add filename to note column of the other\n",
    "\n",
    "                    # otherwise if non-NA rows don't match, not duplicate\n",
    "                    else:    \n",
    "                        df.at[df.index[i], 'dupe'] = False\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# POST PROCESSING\n",
    "\n",
    "# output list of duplicates to be manually checked inspected\n",
    "df_dup = df[df['dupe'] == True]\n",
    "df_dup.to_csv('outputs/dupes.csv', encoding='utf-8')\n",
    "\n",
    "# Remove duplicates\n",
    "print('Number of duplicates removed: ', len(df[df['dupe'] == True]))\n",
    "df = df.drop(df[df['keep'] == False].index)\n",
    "\n",
    "# Merge back in non-duplicates\n",
    "df_dedup = pd.concat([df, df_non_dup], axis=0)\n",
    "\n",
    "# Remove any new columns created: \n",
    "df_dedup = df_dedup.drop(columns=['business_name_2', 'dupe_1', 'dupe', 'keep'])\n",
    "\n",
    "print('Number of rows remaining: ', len(df_dedup))\n",
    "print('Total rows removed from filtering and deduplication: ', len(df_input) - len(df_dedup))\n",
    "df_dedup.to_csv('outputs/deduplicated.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
